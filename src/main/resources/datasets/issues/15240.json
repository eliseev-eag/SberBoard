{
  "url": "https://api.github.com/repos/facebook/react/issues/15240",
  "repository_url": "https://api.github.com/repos/facebook/react",
  "labels_url": "https://api.github.com/repos/facebook/react/issues/15240/labels{/name}",
  "comments_url": "https://api.github.com/repos/facebook/react/issues/15240/comments",
  "events_url": "https://api.github.com/repos/facebook/react/issues/15240/events",
  "html_url": "https://github.com/facebook/react/issues/15240",
  "id": 426597099,
  "node_id": "MDU6SXNzdWU0MjY1OTcwOTk=",
  "number": 15240,
  "title": "Dancing between state and effects - a real-world use case",
  "user": {
    "login": "jlongster",
    "id": 17031,
    "node_id": "MDQ6VXNlcjE3MDMx",
    "avatar_url": "https://avatars2.githubusercontent.com/u/17031?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/jlongster",
    "html_url": "https://github.com/jlongster",
    "followers_url": "https://api.github.com/users/jlongster/followers",
    "following_url": "https://api.github.com/users/jlongster/following{/other_user}",
    "gists_url": "https://api.github.com/users/jlongster/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/jlongster/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/jlongster/subscriptions",
    "organizations_url": "https://api.github.com/users/jlongster/orgs",
    "repos_url": "https://api.github.com/users/jlongster/repos",
    "events_url": "https://api.github.com/users/jlongster/events{/privacy}",
    "received_events_url": "https://api.github.com/users/jlongster/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [
    {
      "id": 710375792,
      "node_id": "MDU6TGFiZWw3MTAzNzU3OTI=",
      "url": "https://api.github.com/repos/facebook/react/labels/Type:%20Discussion",
      "name": "Type: Discussion",
      "color": "fef2c0",
      "default": false
    }
  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 30,
  "created_at": "2019-03-28T16:41:29Z",
  "updated_at": "2019-10-08T21:39:01Z",
  "closed_at": null,
  "author_association": "CONTRIBUTOR",
  "body": "I started this as a gist but Dan mentioned that this would be a good discussion issue so here goes. I've been writing with and refactoring code into hooks for a while now. For 95% of code, they are great and very straight-forward once you get the basic idea. There are still a few more complex cases where I struggle with the right answer though. This is an attempt to explain them.\r\n\r\n## The use case\r\n\r\nThis is a real-world use case from an app I'm building: interacting with a list items. I've simplified the examples into codesandboxes though to illustrate the basic idea.\r\n\r\nHere's the first one: https://codesandbox.io/s/lx55q0v3qz. It renders a list of items, and if you click on any of them, an editable input will appear to edit it (it doesn't save yet). The colored box on the right will change whenever an item rerenders.\r\n\r\nIf you click around in the items, you can see that when changing the edited item, all items rerender. But the `Row` component is wrapped with `React.memo`! They all rerender because the `onEdit` is new each time the app renders, causing all items to rerender.\r\n\r\n## Maintaining callback identity\r\n\r\nWe want `onEdit` to be same function for all future renders. In this case, it's easy because it doesn't depend on anything. We can simply wrap it in `useCallback` with an empty dependencies array:\r\n\r\n```js\r\n  let onEdit = useCallback(id => {\r\n    setEditingId(id);\r\n  }, []);\r\n```\r\n\r\nNow, you can see clicking around only rerenders the necessary items (only those colors change): https://codesandbox.io/s/k33klz68yr\r\n\r\n## Implementing saving\r\n\r\nWe're missing a crucial feature: after editing an item, on blur it should save the value. In my app the way the \"save\" event gets triggered is different, but doing it on blur is fine here.\r\n\r\nTo do this, we create an `onSave` callback in the app and pass it down to each item, which calls it on blur with the new value. `onSave` takes a new item and updates the items array with the new item and sets the `items` state.\r\n\r\nHere is it running: https://codesandbox.io/s/yvl79qj5vj\r\n\r\nYou'll notice that all items are rerendering again when saving. The list rerenders twice when you click another item: first when you click down and the input loses focus, and then again to edit a different item. So all the colors change once, and then only the editing rows color changes again.\r\n\r\nThe reason all of them are rerendering is because `onSave` is now a new callback every render. But we can't fix it with the same technique as `onEdit` because it depends on `items` - so we *have* to create a new callback which closes over `items` otherwise you'd lose previous edits. This is the \"callbacks are recreated too many times\" problem with hooks.\r\n\r\nOne solution is to switch to `useReducer`. Here's that implementation:\r\nhttps://codesandbox.io/s/nrq5y77kj0\r\n\r\nNote that I still wrap up the reducer into `onEdit` and `onSave` callbacks that are passed down to the row. I find passing callbacks to be clearer in most cases, and works with any components in the ecosystem that already expect callbacks. We can simply use `useCallback` with no dependencies though since `dispatch` is always the same.\r\n\r\nNote how that even when saving an item, only the necessary rows rerender.\r\n\r\n## The difference between event handlers and dispatch\r\n\r\nThere's a problem though. This works with a simple demo, but in my real app `onSave` *both* optimistically updates local state and saves it off to the server. It does a side effect.\r\n\r\nIt's something like this:\r\n\r\n```js\r\nasync function onSave(transaction) {\r\n  let { changes, newTransactions } = updateTransaction(transactions, transaction);\r\n  // optimistic update\r\n  setTransactions(newTransactions)\r\n  // save to server\r\n  await postToServer('apply-changes', { changes })\r\n}\r\n```\r\n\r\nThere's a big difference between the phase when an event handler and dispatch is run. Event handlers are run whenever they are triggered (naturally) but the dispatching the action (running `reducer`) happens when rendering. The reducer must be pure because of this.\r\n\r\nHere's the reducer from https://codesandbox.io/s/nrq5y77kj0:\r\n\r\n```js\r\n  function reducer(state, action) {\r\n    switch (action.type) {\r\n      case \"save-item\": {\r\n        let { item } = action;\r\n        return {\r\n          ...state,\r\n          items: items.map(it => (it.id === item.id ? item : it))\r\n        };\r\n      }\r\n      case \"edit-item\": {\r\n        return { ...state, editingId: action.id };\r\n      }\r\n    }\r\n  }\r\n```\r\n\r\nHow is `save-item` also supposed to trigger a side effect? First, item's important to understand these 3 phases:\r\n\r\n```\r\nEvent handler -> render -> commit\r\n```\r\n\r\nEvents are run in the first phase, which causes a render (when dispatches happen), and when everything is finally ready to be flushed to the DOM it does it in a \"commit\" phase, which is when all effects are run (more or less).\r\n\r\nWe need our side effect to run in the commit phase.\r\n\r\n### Option 1\r\n\r\nOne option is to use a ref to \"mark\" the saving effect to be run. Here's the code: https://codesandbox.io/s/m5xrrm4ym8\r\n\r\nBasically you create a flag as a ref:\r\n\r\n```js\r\nlet shouldSave = useRef(false);\r\n```\r\n\r\nLuckily, we've already wrapped the save dispatch into an event handler. Inside `onSave` we mark this flag as true. We can't do it inside of the reducer because it must be pure:\r\n\r\n```js\r\n  let onSave = useCallback(item => {\r\n    shouldSave.current = true;\r\n    dispatch({ type: \"save-item\", item });\r\n  }, []);\r\n```\r\n\r\nFinally, we define an effect that always runs after rendering and checks the flag and resets it:\r\n\r\n```js\r\n  useEffect(() => {\r\n    if (shouldSave.current) {\r\n      // save... all the items to the server?\r\n      post(items)\r\n      shouldSave.current = false;\r\n    }\r\n  });\r\n```\r\n\r\nI thought this option was going to work, but just ran into this issue. We don't know *what* to save anymore. We certainly don't want to send the entire items array to the server! I suppose we could store the item in the ref, but what happens if multiple events are fired before the effect runs? I suppose you could store an array, but... do we really need that?\r\n\r\n### Option 2\r\n\r\n**Note**: I just noticed this option is documented in [How to read an often-changing value from useCallback?](https://reactjs.org/docs/hooks-faq.html#how-to-read-an-often-changing-value-from-usecallback), but I disagree with the tone used. I think this is a fine pattern an better in many cases than `dispatch`, even if it's not quite as robust. Especially since it's not as powerful as callbacks. (see end of this section)\r\n\r\nKeeping around all of the data we need to do the effect might work in some cases, but it feels a little clunky. If we could \"queue up\" effect from the reducer, that would work, but we can't do that. Instead, another option is to embrace callbacks.\r\n\r\nGoing back to the version which used a naive `onSave` which forced all items to rerender (https://codesandbox.io/s/yvl79qj5vj), `onSave` looks like this:\r\n\r\n```js\r\n  let onSave = useCallback(\r\n    item => {\r\n      setItems(items.map(it => (it.id === item.id ? item : it)));\r\n    },\r\n    [items]\r\n  );\r\n```\r\n\r\nThe core problem is that it depends on items. We need to recreate `onSave` because it closes over `items`. But what if it didn't close over it? Instead, let's create a ref:\r\n\r\n```js\r\nlet latestItems = useRef(items);\r\n```\r\n\r\nAnd an effect which keeps it up-to-date with items:\r\n\r\n```js\r\nuseEffect(() => {\r\n  latestItems.current = items\r\n});\r\n```\r\n\r\nNow, the `onSave` callback can reference the ref to always get the up-to-date items. Which means we can memoize it with `useCallback`:\r\n\r\n\r\n```js\r\nlet onSave = useCallback(item => {\r\n  setItems(latestItems.current.map(it => (it.id === item.id ? item : it)));\r\n}, []);\r\n```\r\n\r\nWe are **intentionally** opting to always referencing the latest item. The biggest change with hooks in my opinion is that they are safe by default: an async function will always reference the exact same state that existed at the time they were called. Classes operate the other way: you access state from this.state which can be mutated between async work. Sometimes you want that though so you can maintain callback identity.\r\n\r\nHere is the running sandbox for it: https://codesandbox.io/s/0129jop840. Notice how you can edit items and only the necessary rows rerender, even though it updates `items`. Now, we can do anything we want in our callback, like posting to a server:\r\n\r\n```js\r\nlet onSave = useCallback(item => {\r\n  setItems(latestItems.current.map(it => (it.id === item.id ? item : it)));\r\n  // save to server\r\n  post('/save-item', { item })\r\n}, []);\r\n```\r\n\r\nBasically, if all you need is the latest data since last commit, **callbacks can be memoized as well as reducers**. The drawback is that you need to put each piece of data you need in a ref. If you have lots of pieces of data and only a few simple effects, reducers would be better, but in my case (and I suspect in many others) it's easier to use callbacks with refs.\r\n\r\nIt's nice too because in my real app the save process is more complicated. It needs to get changes back from the server and apply them locally as well, so it looks more like this:\r\n\r\n```js\r\nlet onSave = useCallback(item => {\r\n  setItems(latestItems.current.map(it => (it.id === item.id ? item : it)));\r\n  // save to server\r\n  let changes = await post('/save-item', { item })\r\n  applyChanges(latestItems.current, changes)\r\n}, []);\r\n```\r\n\r\nMaintainability-wise, it's *really* nice to see this whole flow here in one place. Breakin this up to try to manually queue up effects and do a dance with `useReducer` feels much more convoluted.\r\n\r\n### Option 3\r\n\r\nI suppose another option would be to try to \"mark\" the effect to be run in state itself. That way you could do it in `useReducer` as well, and it would look something like this:\r\n\r\n```js\r\nfunction reducer(state, action) {\r\n  switch (action.type) {\r\n    case \"save-item\": {\r\n      let { item } = action;\r\n      return {\r\n        ...state,\r\n        items: state.items.map(it => (it.id === item.id ? item : it)),\r\n        itemsToSave: itemsToSave.concat([item])\r\n      };\r\n    }\r\n    // ...\r\n  }\r\n}\r\n```\r\n\r\nAnd an effect would check the `itemsToSave` state and save them off. The problem is resetting that state - the effect would have to change state, causing a useless rerender, and it's not determistic to make sure that the effect does not run multiple times before `itemsToSave` gets reset.\r\n\r\nIn my experience mixing effects into state, causing renders, make things a lot more difficult to maintain and debug.\r\n\r\n### What's the difference between Option 1 and 2?\r\n\r\nIs there a crucial difference between 1 and 2? Yes, but I'd argue it's not a big deal if you can accept it. Remember these three phases:\r\n\r\n```\r\nEvent handler -> render -> commit\r\n```\r\n\r\nThe big difference is option 1 is doing the side effect in the commit phase, and option 2 is doing it in the event handler phase. Why does this matter?\r\n\r\nIf, for some reason, an item called `onSave` multiple times before the next commit phase happened, option 1 is more robust. A reducer will \"queue up\" the actions and run them in order, updating state in between them, so if you did:\r\n\r\n```js\r\nonSave({ id: 1, name: \"Foo\" })\r\nonSave({ id: 2, name: \"Bar\" })\r\n```\r\n\r\nwhich runs the callback twice immediately, the reducer will process the first save and update the items, and process the second save **passing in the already updated state**.\r\n\r\nHowever, with option 2, when processing the second save **the commit phase hasn't been run yet** so the `latestItems` ref hasn't been updated yet. **The first save will be lost**.\r\n\r\nHowever, the ergonomics of option 2 is much better for many use cases, and I think it's fine to weight these benefits and never need the ability to handle such quick updates. Although concurrent mode might introduce some interesting arguments against that.\r\n\r\n## Another small use case for triggering effects\r\n\r\nIn case this wasn't already long enough, there's a similar use case I'll describe quickly. You can also add new items to the list by editing data in an empty row, and the state of this \"new item\" is tracked separately. \"Saving\" this item doesn't touch the backend, but simply updates the local state, and separate explicit \"add\" action is needed to add it to the list.\r\n\r\nThe hard part is that there is a keybinding for adding the item to the list while editing - something like alt+enter. The problem is I want to coordinate with the state change, so first I want to save the existing field and *then* add to the list. The saving process is complicated so it need to run through that first (I can't just duplicate it all in `onAdd`).\r\n\r\nThis isn't a problem specific to hooks, it's just about coordinating with state changes. When I was working with reducers, I had though that something like this would be neat. Basically when the new items detect that you want to save + add it first an action like `{ type: 'save-item', fields: { name: 'Foo' }, shouldAdd: true }`\r\n\r\n\r\n```js\r\nfunction reducer(state, action) {\r\n  switch (action.type) {\r\n    case \"save-item\": {\r\n      let { fields } = action;\r\n      let newItem = { ...state.newItem, ...fields };\r\n\r\n      if(action.shouldAdd) {\r\n        shouldAdd.current = true\r\n      }\r\n\r\n      return { ...state, newItem };\r\n    }\r\n    // ...\r\n  }\r\n}\r\n```\r\n\r\nwhere `shouldAdd` is a ref that is checked on commit phase and saves the item off to the server. This isn't possible though.\r\n\r\nAnother option would be for the item to call `onAdd` instead of `onSave` when saving + adding, and you could manually call the reducer yourself to process the changes:\r\n\r\n```js\r\nasync function onAdd(fields) {\r\n  let action = { type: 'save-item', fields }\r\n  dispatch(action)\r\n  \r\n  let newItem = reducer(state, action)\r\n  post('/add-item', { newItem });\r\n\r\n}\r\n```\r\n\r\nThis is kind of a neat trick: you are manually running the reducer to get the updated state, and React will run the reducer again whenever it wants.\r\n\r\nSince I ended up liking callbacks for my original problems, I ended up going with a similar approach where I have a ref flag that I just set in `onSave`:\r\n\r\n```js\r\nlet [newItem, setNewItem] = useState({})\r\nlet latestNewItem = useRef(newItem);\r\nlet shouldAdd = useRef(false);\r\n\r\nuseEffect(() => {\r\n  latestNewItem.current = newItem;\r\n})\r\n\r\nuseEffect(() => {\r\n  if(shouldAdd.current) {\r\n    setNewItem({})\r\n    post('/add-item', { newItem })\r\n    shouldAdd.current = false;\r\n  }\r\n})\r\n\r\nlet onSave = useCallback((fields, { add }) => {\r\n  // In my real app, applying the changes to the current item is a bit more complicated than this,\r\n  // so it's not an option to separate on an `onAdd` function that duplicates this logic\r\n  setNewItem({ ...latestNewItem.current, ...fields });\r\n\r\n  // This action also should add, mark the effect to be run\r\n  if(add) {\r\n    shouldAdd.current = true;\r\n  }\r\n}, [])\r\n```\r\n\r\n## Conclusions\r\n\r\nSorry for the length of this. I figure I'd be over-detailed rather than under-detailed, and I've been brewing these thoughts since hooks came out. I'll try to conclude my thoughts here:\r\n\r\n* Effects are **very nice**. It feels like we have easy access to the \"commit\" phase of React, whereas previously it was all in `componentDidUpdate` and not composable at all. Now it's super easy to throw on code to the commit phase which makes coordinating stuff with state easier.\r\n\r\n* Reducers have interesting properties, and I can see how they are fully robust in a concurrent world, but for many cases they are too limited. The ergonomics of implementing many effect-ful workflows with them requires an awkward dance, kind of like when you try to track effect states in local state and split up workflows. Keeping a linear workflow in a callback is not only nice, but necessary in many cases for maintainability.\r\n\r\n* Callbacks can be made memoizable without much work. In many cases I think it's easier to use the ref trick than reducers, but the question is: just *how* dangerous is it? Right now it's not that dangerous, but maybe concurrent mode really is going to break it.\r\n\r\n* If that's the case, we should figure out a better way to weave together effects and state changes.\r\n\r\nI hope all of this made sense. Let me know if something is unclear and I'll try to fix it.",
  "closed_by": null
}
